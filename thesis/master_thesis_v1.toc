\contentsline {section}{\numberline {1}Introduction}{1}
\contentsline {section}{\numberline {2}Preliminaries}{2}
\contentsline {subsection}{\numberline {2.1}Background of Deep Reinforcement Learning}{2}
\contentsline {subsection}{\numberline {2.2}Policy Iteration}{3}
\contentsline {subsection}{\numberline {2.3}Algorithms adapted to the settings of state and action space}{3}
\contentsline {subsection}{\numberline {2.4}Deterministic Policy Gradient Method}{3}
\contentsline {subsection}{\numberline {2.5}Exploration in DDPG}{4}
\contentsline {section}{\numberline {3}Problem Formulation}{5}
\contentsline {subsection}{\numberline {3.1}Self-Triggered Control}{5}
\contentsline {subsection}{\numberline {3.2}Optimal Self-Triggered Control}{6}
\contentsline {section}{\numberline {4}Reinforcement Learning for Optimal Self-Triggered Control}{6}
\contentsline {subsection}{\numberline {4.1}Model Settings}{6}
\contentsline {section}{\numberline {5}Consideration}{6}
\contentsline {subsection}{\numberline {5.1}Linear Case}{7}
\contentsline {subsubsection}{\numberline {5.1.1}Initial Policy}{7}
\contentsline {subsubsection}{\numberline {5.1.2}Learned Policy}{7}
\contentsline {subsubsection}{\numberline {5.1.3}Comparison with Naiive Model Based Control}{8}
\contentsline {subsection}{\numberline {5.2}Non-Linear Case}{8}
\contentsline {subsubsection}{\numberline {5.2.1}Initial Policy}{9}
\contentsline {subsubsection}{\numberline {5.2.2}Learned Policy}{9}
\contentsline {subsection}{\numberline {5.3}Optimality}{10}
\contentsline {subsection}{\numberline {5.4}Approximation Accuracy of Critic}{10}
\contentsline {subsection}{\numberline {5.5}Ingenuity}{11}
\contentsline {section}{\numberline {6}Conclusion}{11}
\contentsline {section}{References}{12}
\contentsline {section}{\numberline {A}Appendix}{12}
